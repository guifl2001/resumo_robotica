{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Códigos úteis para a P2 de Robótica Computacional** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Filtragem de cores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criação de limites para a faixa de cores, utilizando HSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1, g2 = (array([45, 80, 20], dtype=uint8), array([ 65, 255, 255], dtype=uint8))\n",
    "b1, b2 = (array([105,  80,  20], dtype=uint8), array([125, 255, 255], dtype=uint8))\n",
    "\n",
    "def mask(hsv, a1, a2):\n",
    "    return cv2.inRange(hsv, a1, a2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsv = cv2.cvtColor(bgr, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "orange_min = np.array([3,50,50])\n",
    "orange_max = np.array([20, 255,255])\n",
    "\n",
    "mask = cv2.inRange(hsv, orange_min, orange_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para chamar a máscara:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_bgr = cv2.cvtColor(mask, cv2.COLOR_GRAY2BGR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vermelho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segmenta_vermelhos(frame):\n",
    "    frame_hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    cor_menor = np.array([0, 50, 50])\n",
    "    cor_maior = np.array([8, 255, 255])\n",
    "    segmentado_cor = cv2.inRange(frame_hsv, cor_menor, cor_maior)\n",
    "\n",
    "    cor_menor = np.array([172, 50, 50])\n",
    "    cor_maior = np.array([180, 255, 255])\n",
    "    segmentado_cor += cv2.inRange(frame_hsv, cor_menor, cor_maior)\n",
    "    \n",
    "    return segmentado_cor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Azul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blue_menor = np.array([105,  50,  50], dtype=uint8)\n",
    "blue_maior = np.array([125, 255, 255], dtype=uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "green_menor = np.array([45, 50, 50], dtype=uint8) \n",
    "green_maior = np.array([65, 255, 255], dtype=uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ciano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ciano_menor = np.array([80, 50, 50], dtype=uint8)\n",
    "ciano_maior = np.array([100, 255, 255], dtype=uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Magenta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "magenta_menor = np.array([140, 50, 50], dtype=uint8)\n",
    "magenta_maior = np.array([160, 255, 255], dtype=uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Calcular Ponto de Fuga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcula_pf(linha1, linha2):\n",
    "    x0, y0, x1, y1 = linha1\n",
    "    m1 = (y1-y0)/(x1-x0)\n",
    "    h1 = y1 - m1*x1\n",
    "\n",
    "    x0, y0, x1, y1 = linha2\n",
    "    m2 = (y1-y0)/(x1-x0)\n",
    "    h2 = y1 - m2*x1\n",
    "\n",
    "    x_i = (h2 - h1)/(m1 - m2)\n",
    "    y_i = m1*x_i + h1\n",
    "\n",
    "    return int(x_i), int(y_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Calcular distância"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcao que calcula distancia\n",
    "def calcula_dist(p1, p2):\n",
    "    return ((p1[0]-p2[0])**2 + (p1[1]-p2[1])**2)**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - HoughCircles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detecta círculos através do HoughCircles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bordas = auto_canny(mask)\n",
    "circles=cv2.HoughCircles(image=bordas,method=cv2.HOUGH_GRADIENT,dp=1.5,minDist=40,param1=200,param2=100,minRadius=5,maxRadius=200)\n",
    "bordas_rgb = cv2.cvtColor(bordas, cv2.COLOR_GRAY2RGB)\n",
    "output = bordas_rgb\n",
    "\n",
    "if circles is not None:        \n",
    "    circles = np.uint16(np.around(circles))\n",
    "    for i in circles[0,:]:\n",
    "        # draw the outer circle\n",
    "        cv2.circle(output,(i[0],i[1]),i[2],(0,255,0),2)\n",
    "        # draw the center of the circle\n",
    "        cv2.circle(output,(i[0],i[1]),2,(0,0,255),3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Encontra se o símbolo é X ou O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encontra_simbolo(contornos) :\n",
    "    \"\"\"0 - vazio\n",
    "       1 - circulo\n",
    "       2 - x\n",
    "    \"\"\"\n",
    "    if len(contornos) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        for contorno in contornos:\n",
    "            if cv2.contourArea(contorno) > 1000:\n",
    "                if cv2.contourArea(contorno) > 3000:\n",
    "                    return 1\n",
    "                else :\n",
    "                    return 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Centro de Massa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retorna uma tupla (cx, cy) que marca o centro do contorno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def center_of_mass(mask):\n",
    "    M = cv2.moments(mask)\n",
    "    # Usando a expressão do centróide definida em: https://en.wikipedia.org/wiki/Image_moment\n",
    "    if M[\"m00\"] == 0:\n",
    "        M[\"m00\"] = 1\n",
    "    cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "    cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "    return [int(cX), int(cY)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para chamar o centro de massa com uma máscara:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = center_of_mass(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desenha um + (crosshair) centrado no point (tupla (x, y)). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crosshair(img, point, size, color):\n",
    "    \"\"\" color é uma tupla R,G,B uint8 \"\"\"\n",
    "    x,y = point\n",
    "    cv2.line(img,(x - size,y),(x + size,y),color,5)    \n",
    "    cv2.line(img,(x,y - size),(x, y + size),color,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Centro da imagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_image = bridge.compressed_imgmsg_to_cv2(imagem, \"bgr8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cimg = (int(cv_image.shape[1]/2), int(cv_image.shape[0]/2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Controle do robô"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sempre definir v, w. Quando robô vira à direita, w é negativo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = 0.25\n",
    "v = 0.25\n",
    "\n",
    "zero = Twist(Vector3(0,0,0), Vector3(0,0,0))\n",
    "dire = Twist(Vector3(0,0,0), Vector3(0,0,-w))\n",
    "esq = Twist(Vector3(0,0,0), Vector3(0,0,w))\n",
    "frente = Twist(Vector3(v,0,0), Vector3(0,0,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Centralizando o robô no frame e no objeto de escolha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "margem = int(0.15*c_img[0])\n",
    "# Checar se objeto esta a esq\n",
    "if c_objeto[x] < c_img[x] - margem:\n",
    "    pub.publish(esq)\n",
    "    # Checar se objeto esta a dir\n",
    "elif c_objeto[x] > c_img[x] + margem:\n",
    "    pub.publish(dire)\n",
    "else: \n",
    "    # Se centralizado, seguir em frente\n",
    "    pub.publish(frente)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trabalhando com estados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROCURANDO, CENTRALIZANDO, AVANCANDO, PARADO = 1, 2, 3, 4\n",
    "\n",
    "state = PROCURANDO\n",
    "\n",
    "def printstate(state):\n",
    "    if state == PROCURANDO:\n",
    "        print (\"PROCURANDO\")\n",
    "    elif state == CENTRALIZANDO:\n",
    "        print (\"CENTRALIZANDO\")\n",
    "    elif state == AVANCANDO:\n",
    "        print (\"AVANCANDO\")\n",
    "    elif state == PARADO:\n",
    "        print (\"PARADO\")\n",
    "\n",
    "dt = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while not rospy.is_shutdown():\n",
    "    printstate(state)\n",
    "    if state == PROCURANDO:\n",
    "        velocidade_saida.publish(rot)\n",
    "        if circle_visible == True:\n",
    "            state = CENTRALIZANDO\n",
    "            velocidade_saida.publish(zero)\n",
    "            rospy.sleep(dt)\n",
    "    if state == CENTRALIZANDO:          \n",
    "        print(\"Delta\", circle_delta)\n",
    "        atuacao = -circle_delta/275.0*0.3\n",
    "        rot = Twist(Vector3(0,0,0), Vector3(0,0,atuacao))\n",
    "        velocidade_saida.publish(rot)            \n",
    "        if abs(circle_delta) < delta_tolerance:\n",
    "            state = AVANCANDO\n",
    "            velocidade_saida.publish(zero)              \n",
    "            rospy.sleep(dt)\n",
    "    elif state == AVANCANDO:\n",
    "        velocidade_saida.publish(frente)\n",
    "        if metro - dist_tolerance < distancia < metro + dist_tolerance:\n",
    "            state = PARADO\n",
    "            velocidade_saida.publish(zero)\n",
    "            rospy.sleep(dt)\n",
    "    elif state == PARADO:\n",
    "        velocidade_saida.publish(zero)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - *Função go_to()*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def go_to(x1, y1, pub):\n",
    "    x0 = x # Vai ser atualizado via global e odometria em um thread paralelo\n",
    "    y0 = y # global e odometria (igual ao acima)\n",
    "    delta_x = x1 - x0\n",
    "    delta_y = y1 - y0\n",
    "\n",
    "    h = math.sqrt(delta_x**2 + delta_y**2) # Distancia ate o destino. Veja \n",
    "    # https://web.microsoftstream.com/video/f039d50f-3f6b-4e01-b45c-f2bffd2cbd84\n",
    "\n",
    "    while h > 0.3:      \n",
    "        print(\"Goal \", x1,\",\",y1)\n",
    "        # Rotacao\n",
    "        ang_goal = math.atan2(delta_y,delta_x)  \n",
    "        ang_atual = rad_z # rad_z muda automaticamente via global e odometria\n",
    "        dif_ang = ang_goal - ang_atual\n",
    "        delta_t = abs(dif_ang)/v_ang\n",
    "        # Twist\n",
    "        if dif_ang > 0.0:\n",
    "            vel_rot = Twist(Vector3(0,0,0), Vector3(0,0,v_ang))\n",
    "        elif dif_ang <=0:\n",
    "            vel_rot = Twist(Vector3(0,0,0), Vector3(0,0,-v_ang))    \n",
    "        # publish\n",
    "        pub.publish(vel_rot)\n",
    "        # sleep\n",
    "        rospy.sleep(delta_t)\n",
    "        zero = Twist(Vector3(0,0,0), Vector3(0,0,0))\n",
    "        pub.publish(zero)\n",
    "        rospy.sleep(0.1)\n",
    "        # Translacao\n",
    "        delta_t = h/v_lin\n",
    "        linear = Twist(Vector3(v_lin,0,0), Vector3(0,0,0))\n",
    "        pub.publish(linear)\n",
    "        rospy.sleep(delta_t)\n",
    "        pub.publish(zero)\n",
    "        rospy.sleep(0.1)  \n",
    "        x0 = x\n",
    "        y0 = y\n",
    "        delta_x = x1 - x0\n",
    "        delta_y = y1 - y0\n",
    "        h = math.sqrt(deltScreencast from 15 06 2020 17:39:42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MobileNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essa função recebe uma imagem colorida e devolve o objeto encontrado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"MobileNetSSD_deploy.caffemodel\"\n",
    "proto = \"MobileNetSSD_deploy.prototxt.txt\"\n",
    "\n",
    "video = \"animais_caixas.mp4\" #Substituir pelo vídeo que quer\n",
    "\n",
    "def detect(frame):\n",
    "    image = frame.copy()\n",
    "    (h, w) = image.shape[:2]\n",
    "    blob = cv2.dnn.blobFromImage(cv2.resize(image, (300, 300)), 0.007843, (300, 300), 127.5)\n",
    "\n",
    "    # pass the blob through the network and obtain the detections and\n",
    "    # predictions\n",
    "    print(\"[INFO] computing object detections...\")\n",
    "    net.setInput(blob)\n",
    "    detections = net.forward()\n",
    "\n",
    "    results = []\n",
    "\n",
    "    # loop over the detections\n",
    "    for i in np.arange(0, detections.shape[2]):\n",
    "        # extract the confidence (i.e., probability) associated with the\n",
    "        # prediction\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "\n",
    "        # filter out weak detections by ensuring the `confidence` is\n",
    "        # greater than the minimum confidence\n",
    "\n",
    "\n",
    "        if confidence > CONFIDENCE:\n",
    "            # extract the index of the class label from the `detections`,\n",
    "            # then compute the (x, y)-coordinates of the bounding box for\n",
    "            # the object\n",
    "            idx = int(detections[0, 0, i, 1])\n",
    "            box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "            (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "\n",
    "            # display the prediction\n",
    "            label = \"{}: {:.2f}%\".format(CLASSES[idx], confidence * 100)\n",
    "            print(\"[INFO] {}\".format(label))\n",
    "            cv2.rectangle(image, (startX, startY), (endX, endY),\n",
    "                COLORS[idx], 2)\n",
    "            y = startY - 15 if startY - 15 > 15 else startY + 15\n",
    "            cv2.putText(image, label, (startX, y),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.5, COLORS[idx], 2)\n",
    "\n",
    "            results.append((CLASSES[idx], confidence*100, (startX, startY),(endX, endY) ))\n",
    "\n",
    "    # show the output image\n",
    "    return image, results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recebe um mesmo frame em BGR e como máscara binária, encontra o maior contorno na máscara e desenha o contorno e a caixa envoltória na BGR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bounding_box(mask, bgr, color = (0,0,255)):\n",
    "    contornos, arvore = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE) \n",
    "    cv2.drawContours(bgr, contornos, -1, [255, 255, 0], 3);\n",
    "    maior = None\n",
    "    maior_area = 0\n",
    "    for c in contornos:\n",
    "        area = cv2.contourArea(c)\n",
    "        if area > maior_area:\n",
    "            maior_area = area\n",
    "            maior = c\n",
    "    cv2.drawContours(bgr, [maior], -1, [0, 255, 255], 5);\n",
    "    \n",
    "    # Inicializando com valores fora da faixa que vai ser encontrada\n",
    "    max_x = -1\n",
    "    min_x = 10000\n",
    "    max_y = -1\n",
    "    min_y = 10000\n",
    "    \n",
    "    # imprimindo o contorno entendemos sua estrutura\n",
    "    \n",
    "    for p in maior:\n",
    "        if p[0][0] > max_x:\n",
    "            max_x = p[0][0]\n",
    "        \n",
    "        if p[0][0] < min_x:\n",
    "            min_x = p[0][0]\n",
    "            \n",
    "        if p[0][1] < min_y:\n",
    "            min_y = p[0][1]\n",
    "        \n",
    "        if p[0][1] > max_y:\n",
    "            max_y = p[0][1]\n",
    "    \n",
    "    minp = (min_x, min_y)\n",
    "    maxp = (max_x, max_y)\n",
    "    \n",
    "    cv2.rectangle(bgr, minp, maxp, color, 3)\n",
    "    \n",
    "    return minp, maxp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recebe uma tupla de resultados da mobilenet, por exemplo ('cat', 98.16664457321167, (650, 237), (793, 436)) e uma caixa definida por minp e maxp e diz se o animal da tupla está contido na caixa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_in_mask(tupla_mobilenet, minp, maxp):\n",
    "    t = tupla_mobilenet\n",
    "    net_min = t[2]\n",
    "    net_max = t[3]\n",
    "    \n",
    "    x = 0\n",
    "    y = 1\n",
    "    \n",
    "    print(net_min, net_max, minp, maxp)\n",
    "    \n",
    "    if (net_min[x] > minp[x]) and (net_max[x] < maxp[x]) and (net_min[y] > minp[y]) and (net_max[y] < maxp[y]):\n",
    "        return True\n",
    "    else:\n",
    "        return False    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Depois da inicialização do programa (if name == main):*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializa a aquisição da webcam\n",
    "cap = cv2.VideoCapture(video)\n",
    "\n",
    "# cria a rede neural\n",
    "net = cv2.dnn.readNetFromCaffe(proto, model)\n",
    "\n",
    "CLASSES = [\"background\", \"aeroplane\", \"bicycle\", \"bird\", \"boat\",\n",
    "    \"bottle\", \"bus\", \"car\", \"cat\", \"chair\", \"cow\", \"diningtable\",\n",
    "    \"dog\", \"horse\", \"motorbike\", \"person\", \"pottedplant\", \"sheep\",\n",
    "    \"sofa\", \"train\", \"tvmonitor\"]   \n",
    "\n",
    "CONFIDENCE = 0.7\n",
    "COLORS = np.random.uniform(0, 255, size=(len(CLASSES), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Texto na tela"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cv(bgr, pos, text, fontscale=1, thickness=1):\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX    \n",
    "    color=(255,255,255)    \n",
    "    mensagem = \"{}\".format(text)\n",
    "    cv2.putText(bgr, mensagem, pos, font, fontscale, color, thickness, cv2.LINE_AA) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chamando a função de texto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_cv(mask_bgr, centro, str((graus/6)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BRISK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir o vídeo/foto a ser trabalhado\n",
    "video = \"video.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria o detector BRISK\n",
    "brisk = cv2.BRISK_create()\n",
    "\n",
    "# Encontra os pontos únicos (keypoints) nas duas imagems\n",
    "kp1, des1 = brisk.detectAndCompute(img_original ,None)\n",
    "\n",
    "# Configura o algoritmo de casamento de features que vê *como* o objeto que deve ser encontrado aparece na imagem\n",
    "bf = cv2.BFMatcher(cv2.NORM_HAMMING)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_homography_draw_box(kp1, kp2, img_cena, good):\n",
    "    \n",
    "    out = img_cena.copy()\n",
    "    \n",
    "    src_pts = np.float32([ kp1[m.queryIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "    dst_pts = np.float32([ kp2[m.trainIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "\n",
    "\n",
    "    # Tenta achar uma trasformacao composta de rotacao, translacao e escala que situe uma imagem na outra\n",
    "    # Esta transformação é chamada de homografia \n",
    "    # Para saber mais veja \n",
    "    # https://docs.opencv.org/3.4/d9/dab/tutorial_homography.html\n",
    "    M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC,5.0)\n",
    "    matchesMask = mask.ravel().tolist()\n",
    "\n",
    "\n",
    "    \n",
    "    h,w = img_original.shape\n",
    "    # Um retângulo com as dimensões da imagem original\n",
    "    pts = np.float32([ [0,0],[0,h-1],[w-1,h-1],[w-1,0] ]).reshape(-1,1,2)\n",
    "\n",
    "    # Transforma os pontos do retângulo para onde estao na imagem destino usando a homografia encontrada\n",
    "    dst = cv2.perspectiveTransform(pts,M)\n",
    "   \n",
    "    corners = find_box_corners(dst)\n",
    "        \n",
    "\n",
    "    # Desenha um contorno em vermelho ao redor de onde o objeto foi encontrado\n",
    "    img2b = cv2.polylines(out,[np.int32(dst)],True,(255,255,0),5, cv2.LINE_AA)\n",
    "    \n",
    "    return img2b, corners\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O exemplo abaixo carrega duas imagens. A `img_original` é o objeto a ser encontrado, e a `img_cena` contém uma cena que contém o objeto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Número mínimo de pontos correspondentes\n",
    "MIN_MATCH_COUNT = 10\n",
    "\n",
    "cena_bgr = cv2.imread(\"arduino_mesa.jpg\") # Imagem do cenario\n",
    "original_bgr = book_bgr\n",
    "\n",
    "# Versões RGB das imagens, para plot\n",
    "original_rgb = cv2.cvtColor(original_bgr, cv2.COLOR_BGR2RGB)\n",
    "cena_rgb = cv2.cvtColor(cena_bgr, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match(des1, cena_bgr):                \n",
    "\n",
    "    img_cena = cv2.cvtColor(cena_bgr, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    kp2, des2 = brisk.detectAndCompute(img_cena,None)\n",
    "\n",
    "\n",
    "    # Tenta fazer a melhor comparacao usando o algoritmo\n",
    "    matches = bf.knnMatch(des1,des2,k=2)\n",
    "\n",
    "    # store all the good matches as per Lowe's ratio test.\n",
    "    good = []\n",
    "    for m,n in matches:\n",
    "        if m.distance < 0.7*n.distance:\n",
    "            good.append(m)\n",
    "\n",
    "    framed = cena_bgr\n",
    "    bbox=((0,0),(0,0)) # Caixa vazia de retorno padrão\n",
    "    \n",
    "    if len(good)>MIN_MATCH_COUNT:\n",
    "        # Separa os bons matches na origem e no destino\n",
    "        print(\"Matches found\")    \n",
    "        framed, bbox = find_homography_draw_box(kp1, kp2, cena_bgr, good)\n",
    "    else:\n",
    "        print(\"Not enough matches are found - %d/%d\" % (len(good),MIN_MATCH_COUNT))\n",
    "    return framed, bbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*---------------------------------------------------------------------------------------------------------------------------*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funções úteis para resoluções de exercícios em BRISK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Conta píxeis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recebe uma máscara binária e 2 pontos e conta quantos pixels são brancos na máscara."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_pixels(mask, ponto1, ponto2, txt_color):\n",
    "    x1, y1 = ponto1\n",
    "    x2, y2 = ponto2\n",
    "\n",
    "    font = cv2.FONT_HERSHEY_COMPLEX_SMALL\n",
    "    # Selecionando só a região da imagem com o cachorro\n",
    "    submask = mask[y1:y2,x1:x2]\n",
    "    # Somando os pixels 255 e dividindo por 255 para saber quantos são\n",
    "    pixels = np.sum(submask)/255\n",
    "    # O resto é só plot\n",
    "    rgb_mask = cv2.cvtColor(mask, cv2.COLOR_GRAY2RGB)\n",
    "    cv2.rectangle(rgb_mask, ponto1, ponto2, (255,0,0), 3)\n",
    "    cv2.putText(rgb_mask, \"%s:%d\"%(txt_color, pixels), (int((x1+x2)/2), int((y1+y2)/2)), font, 1, (0,255,0),1,cv2.LINE_AA)\n",
    "    return pixels, rgb_mask\n",
    "    #plt.imshow(submask, cmap=\"Greys_r\", vmin=0, vmax=255)\n",
    "    #plt.title(\"(%d , %d) (%d,%d)\"%(x1, y1, x2, y2))\n",
    "    #plt.show()\n",
    "    \n",
    "\n",
    "tolerancia = 0.25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Transfroma representação de pontos em matriz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transforma uma representação de 4 pontos em uma matriz usada pelo cv2 perspectiveTransform em uma lista de tuplas (x,y).        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_list(pts):\n",
    "    # Remova os comentários para entender como os pontos são armazenados na cv2\n",
    "    # print(\"Points:\\n\", pts) # Para salientar como encontrar os pontos\n",
    "    # print(\"dst.shape: \", pts.shape)\n",
    "    l = []\n",
    "    for p in pts:\n",
    "        x = p[0][0]\n",
    "        y = p[0][1]\n",
    "        l.append((x,y))\n",
    "    return l\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Bounding box"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encontra os cantos da bounding box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_box_corners(pts):        \n",
    "    \"\"\" Versao mais didatica \"\"\"\n",
    "    l = make_list(pts)\n",
    "    print(\"l: \", l)\n",
    "    x_coords = [p[0] for p in l]\n",
    "    y_coords = [p[1] for p in l]\n",
    "    x_min = int(min(x_coords))\n",
    "    x_max = int(max(x_coords))\n",
    "    y_min = int(min(y_coords))\n",
    "    y_max = int(max(y_coords))       \n",
    "    return ((x_min,y_min),(x_max,y_max))\n",
    "\n",
    "def find_box_corners2(pts):\n",
    "    return ((min(pts[:,:,0]), min(pts[:,:,1])), (max(pts[:,:,0]), max(pts[:,:,1])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Processa frame (adaptável para cada código, segue o exemplo do ex2 da p2_2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recebe um frame BGR, procura seu padrão e calcula a área do padrão encontrado na imagem. Depois separa o canal vermelho contando a quantidade e proporção de pixels vermelhos. Se a proporção for maior que o que foi desejado, printa a mesnagem na tela."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processa(frame):\n",
    "    \"\"\"Recebe um frame BGR\"\"\"\n",
    "    # Procura o padrao\n",
    "    red_match, corners = match(des1, frame)\n",
    "    # Calcula a área do padrão encontrado na imagem\n",
    "    area_found = area(corners[0], corners[1])\n",
    "    \n",
    "    proporcao = -1 # inicializando com um valor imnpossível\n",
    "    \n",
    "    # Separa o canal vermelho\n",
    "    red = segmenta_vermelhos(frame)\n",
    "    \n",
    "    # Conta a quantidade e a proporcao de vermelhos\n",
    "    qtd_vermelhos, saida_count = count_pixels(red,corners[0],corners[1], (0,0,255))  \n",
    "\n",
    "\n",
    "    cv2.imshow(\"debug\", saida_count)\n",
    "    \n",
    "    if area_found>0:\n",
    "        proporcao = qtd_vermelhos/area_found    \n",
    "    \n",
    "    if area_found > 0 and proporcao > tolerancia:\n",
    "        cv2.rectangle(red_match, corners[0],corners[1], (0,0,255), 10)\n",
    "        font = cv2.FONT_HERSHEY_COMPLEX_SMALL        \n",
    "        cv2.putText(red_match, \"Encontrado\", (corners[0][0], corners[1][1]), font, 3, (0,0,255),2,cv2.LINE_AA)\n",
    "        print(\"returning red_match\")\n",
    "        return red_match\n",
    "    else:\n",
    "        return frame\n",
    "\n",
    "def area(pt1, pt2):\n",
    "    return abs((pt1[0] - pt2[0])*(pt1[1] - pt2[1]))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
